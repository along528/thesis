
%might try to show that fake estimate can be approximated just
%by TTL inputs, maybe using a histogram
%they are produced under ~/analysis/www/scripts/plot/plotDataMxM_Comparisons.py


The physics objects reconstructed by the ATLAS detector are selected
as described in \sec\ref{sec:object_selection} in order to 
identify ``real'' particles or physics processes produced in the collisions
of the LHC. Still, this identification is not perfect. A jet,
for instance, perhaps from a charged pion, could leave a single
track in the inner detector along with a narrow energy deposit in the
EM calorimeter; a very similar signature to an electron. Or, 
a \bee-hadron, could decay into a final state with a high energy muon,
making it difficult to distinguish from a muon produced in the hard interaction.
We call these mis-reconstructed objects, ``fake'' objects. 
In this analysis we are primarily interested in the subset of these 
which resemble leptons, like those described above; we refer
to these as ``fake'' leptons.

Fake leptons might be considered physics objects which have 
``slipped through the cracks''. In particle physics it is 
never the case that the features describing 
a given particle are completely separable
from another, even hypothetically. Instead,
the characterstic features for a type of particle will 
overlap with that of other particles. For example, both electrons
and jets are characterized in part by the presence of calorimeter
deposits in the EM calorimeter. 
The calorimeter deposits form a cone 
pointing back to the collision point, and the radius
of this cone will follow some distribution. On average,
the deposit from an electron will have a smaller radius 
than that of a jet. So, on average the radius of calorimeter
deposits can be used to distinguish between the two physics
processes. But the overlap of these two distributions is 
signifiant enough that using this radius alone
will give an unsatisfactorily high error rate for identification.
The error rate can be improved by adding information 
from the inner detector, and so on, further reducing
the error rate but never reaching zero.
So, while rare, the large number of collisions produced by the LHC
means that the measurement of fake leptons will inevitably occur. 
Thus, we must take them into account.

The modeling of these fake leptons are in general 
heavily dependent upon the conditions of the detector. 
The detector is described in MC simulation using \geant, thus
it is possible and relatively straightforward 
to model these processes using MC directly.
However, in practice, this usually proves to be inadequate.
While sophisticated, models of the detector are inevitably imperfect.
Besides that, some of the effects which produce fake leptons 
are so rare that it may be difficult to generate enough MC
collisions to obtain adequate statistics.
The dataset from the LHC, however, has an extremely large sample size
and uses the detector itself, not a model. Thus, it has all of the 
information we need. The trick is then how to extract this information
for the signal regions of interest in an accurate and unbiased way.


We choose to use the Generalized Matrix Method~\cite{Gillam:2014xua}, 
which may estimate from data the contribution of any combination
fake and real leptons. It has been implemented previously in 
\cite{Arguin:1558979}. A simpler version of the matrix
method, which is restricted to the estimaton of events with 
exactly one fake lepton, 
was first implemented by ATLAS in \cite{ATLAS-CONF-2010-087}, 
and variations of the method have been implemented in numerous publications
by ATLAS ever since (though less often by CMS).
In essence, the method relese on the definition of two different selections,
referred to as ``tight'' and ``loose'', defined such that
``real'' leptons are more likely to pass the ``tight'' selection
than ``fake'' leptons. If the probability of the ``real'' and 
``fake'' leptons to pass these selections can be determined (typically
in control regions), 
then in principle the easily defined
``tight'' and ``loose'' selections may be used
as a proxy
to extract an estimate of the 
``real'' and ``fake'' lepton
contributions in a region of one's choosing.
The method is described in more detail below.



\subsubsection{Generalized Matrix Method}
\label{sec:mxm}

The Generalized Matrix Method allows one to extract from data the expected
number of events with any combination of fake and real leptons.
For any given selection, some fraction of the events will have 
real leptons, fake leptons, or some combination of the two.
For a selection with exactly one lepton, the lepton 
can simply be either real or fake.  Suppose one then defines
two orthogonal single lepton
selections with in general different combinations of real and fake leptons.
Furthermore, design one of the selections to be much more likely to have
real leptons than fake leptons, usually taken 
to be the signal region selection. We will call this the ``tight'' selection.
We can measure directly the number of events in the data that
pass this ``tight'' selection and call it $n_T$. Choose the other selection
to have a different composition of real and fake leptons. Since the 
``tight'' selection is enriched in real leptons, this can be achieved
if this other selection has a larger proportion of fake leptons, though
not necessarily dominated by fake leptons. We will call this the
``loose'' selection and designate the number of events measured
in this selection as $n_L$. The total number of real leptons that fall in 
both regions can be called $n_R$. The probability that one of these
real leptons passes the tight selection is called the 
real efficiency, or sometimes the real rate, and is denoted by 
$\real$. Similarly, the total number of fake leptons 
that fall in both regions is denoted $n_F$ and the probability 
that one of these fake leptons passes the tight selection is 
calle the fake efficiency, or fake rate, and is 
denoted by $\fake$. The condition that
more real leptons pass the tight selection can thus be summarized by saying
that $\real>>\fake$ be true.
The expected values\footnote{The issue
of deriving an expected value instead from a measured value
is an important one which shows how this method can be break down 
as will be discusssed shortly.} of  $n_T$ and $n_L$,
denoted $\langle n_T\rangle$ and $\langle n_L\rangle$,
can be related to $n_R$ and $n_F$ using these rates via a system of
equations:
\begin{align}
  \label{eq:mxm_single}
  \begin{pmatrix} \langle n_T\rangle \\ \langle n_L\rangle \end{pmatrix} 
  &= 
  \begin{pmatrix}
  \real & \fake \\ \realbar & \fakebar
  \end{pmatrix} 
  \begin{pmatrix} n_R \\ n_F \end{pmatrix}
\end{align}
where we have introduced the notation $\realbar = 1-\real$
and $\fakebar =1-\fake$.
Note that this equation is a function of the measured values of
$n_R$ and $n_F$ which we are actually seeking to find in terms of the 
expectations of $n_T$ and $n_L$. Thus, it is in fact more
useful to solve for $n_R$ and $n_F$ by taking the inverse:
\begin{align}
  \label{eq:mxm_single_inverted}
  \begin{pmatrix} n_R \\ n_F \end{pmatrix} 
  &= 
  \frac{1}{\real-\fake}
  \begin{pmatrix}
  \fakebar & -\fake \\ -\realbar & \real
  \end{pmatrix} 
  \begin{pmatrix} \langle n_T\rangle \\ \langle n_L\rangle \end{pmatrix}
\end{align}

So far everything is exact and as long as the condition
that $\real>>\fake$ is true,
as it should be by construction, 
then there is no risk of encountering the singular condition
when $\real=\fake$.
But in the matrix method, \eqn\eqref{eq:mxm_single_inverted}
we wish to use the \emph{measured} values of $n_T$
and $n_T$ to derive an \emph{estimate} of the expectation
for $n_R$ and $n_F$, denoted $\hat{n}_R$ and $\hat{n}_F$. 
Thus, in a rather \emph{ad hoc} way 
we interpert the equation as follows:
\begin{align}
  \label{eq:mxm_single_inverted_approx}
  \begin{pmatrix} \langle n_R\rangle \\ \langle n_F\rangle \end{pmatrix} 
  &\approx
  \begin{pmatrix} \hat{n}_R \\ \hat{n}_F \end{pmatrix} 
  &= 
  \frac{1}{\real-\fake}
  \begin{pmatrix}
  \fakebar & -\fake \\ -\realbar & \real
  \end{pmatrix} 
  \begin{pmatrix} n_T \\ n_L \end{pmatrix}
\end{align}
This equation solves for the estimators, $\hat{n}_R$ and $\hat{n}_F$,
as a function of the measured values $n_T$ and $n_L$, as well 
as the rates. The estimators are in general only approximately equal
to the expected values, as discussed in \cite{Gillam:2014xua}.
This approximation can break down, sometimes even giving negative values
for the estimate.  Though it should be adequate if the number
of events falling in the ``tight'' and ``loose'' selections are 
not too small.
We will assume that the method holds, but these concerns are important
to keep in mind whenever using this method.


We now have a way to approximately solve for the estimate
of the real and fake lepton contributions to a single lepton 
selection in our data sample, but ultimately we are interested
in an estimate of 
the number of fake leptons that fall into our tight selection, call this
estimate $\hat{f}_{T}$ and the number of fake leptons
that are loose, $\hat{f}_{L}$. 
This estimate can be solved for then in a straightforward way, by 
selecting only the estimated component of fakes.
\begin{align}
  \begin{pmatrix} \hat{f}_T \\ \hat{f}_L \end{pmatrix} 
  &= 
  \begin{pmatrix}
  \real & \fake \\ \realbar & \fakebar
  \end{pmatrix} 
  \begin{pmatrix} 0\\ \hat{n}_F \end{pmatrix}
  &=
  \begin{pmatrix}
  \real & \fake \\ \realbar & \fakebar
  \end{pmatrix} 
  \begin{pmatrix}
  0 & 0\\ 0 & 1
  \end{pmatrix} 
  \begin{pmatrix} \hat{n}_R\\ \hat{n}_F \end{pmatrix}
\end{align}
Substituting in for equation \eqn\eqref{eq:mxm_single_inverted_approx}
gives an expression for the expected number of tight and loose
selected fake leptons as determined from the rates and the measured
value of tight and loose leptons:
\begin{align}
  \label{eq:mxm_final_single}
  \begin{pmatrix} \hat{f}_T \\ \hat{f}_L \end{pmatrix} 
  &=
  \begin{pmatrix}
  \real & \fake \\ \realbar & \fakebar
  \end{pmatrix} 
  \begin{pmatrix}
  0 & 0\\ 0 & 1
  \end{pmatrix} 
  \frac{1}{\real-\fake}
  \begin{pmatrix}
  \fakebar & -\fake \\ -\realbar& \real
  \end{pmatrix} 
  \begin{pmatrix} n_T\\ n_L \end{pmatrix}
\end{align}
And then we may simply pluck out the estimated number of tight leptons
from fakes, which is usually of interest:
\begin{align}
  \label{eq:mxm_final_single2}
  \begin{pmatrix} \hat{f}_T \\ 0 \end{pmatrix} 
  &=
  \begin{pmatrix}
  1 & 0\\ 0 & 0
  \end{pmatrix} 
  \begin{pmatrix}
  \real & \fake \\ \realbar & \fakebar
  \end{pmatrix} 
  \begin{pmatrix}
  0 & 0\\ 0 & 1
  \end{pmatrix} 
  \frac{1}{\real-\fake}
  \begin{pmatrix}
  \fakebar & -\fake \\ -\realbar& \real
  \end{pmatrix} 
  \begin{pmatrix} n_T\\ n_L \end{pmatrix}
\end{align}
Evaluating the expression for $\hat{f}_T$ gives:
\begin{align}
\hat{f}_T &= \frac{\fake}{\real-\fake} \Big( \real(n_T+n_L) - n_T \Big)  \\
           &= \Big( \frac{\fake}{\real-\fake} 
	      -\real\Big) n_T 
	      + \Big(\frac{\fake}{\real-\fake} \real \Big)n_L\\
           &= w_T~n_T + w_L~n_L
\end{align}
where in the last line we have reorganized the coefficients in front
of $n_T$ and $n_T$ into parameters $w_T$ and $w_L$ which are depedent
upon the rates. Practically, the final estimate of $\hat{f}_T$
can be determined by looping over each event in data, weighting each event
using either $w_T$ for those passing the tight selection and
$w_L$ for those passing the loose selection, and then 
summing up all of the weighted events.  This is a very useful 
strategy since it allows one to compute the estimate on the fly
using a setup similar to the one already processing the data itself. %reword?
Note that since $\real>>\fake$ and $0<\real<1$,
$w_T$ will always be negative. Thus the method will produce negative weights.
This is not a concern as long as we keep in mind that the sum
is the only thing that is ultimately of interest.
However, it is worth noticing that the total estimate can itself
be negative when $\real n_L< \realbar n_T$.
Though this can in general be avoided as long as $\real$
is close to unity and if $n_L$ is
as large or larger than $n_T$, which should usually be the case
anyway. In any case, it shows that it is possible to get negative
results if the proper conditions are not met.

It will prove useful to rewrite \eqn\eqref{eq:mxm_final_single}
in a more general form:
\begin{equation}
\label{eq:mxm_general}
\hat{F} = \mathbf{\Phi}\mathbf{W}\mathbf{\Phi}^{-1} N
\end{equation}
where for the single lepton case
$N^T=\begin{pmatrix} n_T & n_L\end{pmatrix}$ 
and 
$\hat{F}^T=\begin{pmatrix} \hat{f}_T & \hat{f}_L\end{pmatrix}$.\footnote{A 
superscript $T$ refers to the vector transpose.}
The quantity $\mathbf{\Phi}$ is the matrix from \eqn\eqref{eq:mxm_single}
\begin{equation}
\mathbf{\Phi} = 
  \begin{pmatrix}
  \real& \fake\\ \realbar& \fakebar
  \end{pmatrix} 
\end{equation}
and $\mathbf{\Phi}^{-1}$ is its inverse. Finally, $\mathbf{W}$
is the fake selection matrix which in this case is identified with
\begin{equation}
\mathbf{W}=\begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix}
\end{equation}
And if we want only the estimate of the remaining tight leptons
like in \eqn\eqref{eq:mxm_final_single2}
then we can do 
\begin{equation}
\label{eq:mxm_general_tight}
\hat{T} = \mathbf{M}\mathbf{\Phi}\mathbf{W}\mathbf{\Phi}^{-1} N
\end{equation}
where $\hat{T}^T=\begin{pmatrix} \hat{f}_T & 0 \end{pmatrix}$
and $\mathbf{M}$ is the tight selection matrix:
\begin{equation}
\mathbf{M}=\begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}
\end{equation}




So far we have considered only the rates
in a single category or bin and for a single lepton. 
But this process can be extended easily for different bins, 
the lepton \pt~for instance, with different rates 
by simply keeping track of each bin using an index. For example,
in bin $i$, one would measure the rates $\real^i$ and $\fake^i$
as well as the values $n_T^i$ and $n_L^i$ to arrive at the expectations
for in bin $i$ of $\hat{f}^i_T$ and $\hat{f}^i_L$.
Equation\eqref{eq:mxm_general} then becomes 
$\hat{F}^i = \mathbf{\Phi}^i\mathbf{W}(\mathbf{\Phi}^{-1})^i N^i$.
One may then sum over all the of the bins to get a total estimate
if desired.

The matrix method can be also extended to multiple leptons,
resulting in the generalised matrix method. 
Consider the three lepton case, which is most relevant to this
analysis. 
Equation \eqref{eq:mxm_general_tight} becomes
\begin{equation}
\hat{T}^{ijk} = \mathbf{M}\mathbf{\Phi}^{ijk}\mathbf{W}(\mathbf{\Phi}^{-1})^{ijk} N^{ijk}
\end{equation}
where each of the three leptons can be in separate bins $i$, $j$, and $k$.
The matrix $\mathbf{\Phi}^{ijk}$
can by constructed by taking the Kronecker product (cite) (denoted by $\otimes$)
of the individual single lepton matrices of rates for each lepton:
\begin{align}
  \mathbf{\Phi}^{ijk} &=
  \begin{pmatrix}
  \real^i & \fake^i \\ \realbar^i & \fakebar^i
  \end{pmatrix} 
  \otimes
  \begin{pmatrix}
  \real^j & \fake^j \\ \realbar^j & \fakebar^j
  \end{pmatrix} 
  \otimes
  \begin{pmatrix}
  \real^k & \fake^k \\ \realbar^k & \fakebar^k
  \end{pmatrix} \\
  &=
  \begin{pmatrix} 
  \real^i\real^j\real^k  &
  \real^i\real^j\fake^k  &
  \real^i\fake^j\real^k  &
  \real^i\fake^j\fake^k  &
  \fake^i\real^j\real^k  &
  \fake^i\real^j\fake^k  &
  \fake^i\fake^j\real^k  &
  \fake^i\fake^j\fake^k  \\
  \real^i\real^j\realbar^k  &
  \real^i\real^j\fakebar^k  &
  \real^i\fake^j\realbar^k  &
  \real^i\fake^j\fakebar^k  &
  \fake^i\real^j\realbar^k  &
  \fake^i\real^j\fakebar^k  &
  \fake^i\fake^j\realbar^k  &
  \fake^i\fake^j\fakebar^k  \\
  \real^i\realbar^j\real^k  &
  \real^i\realbar^j\fake^k  &
  \real^i\fakebar^j\real^k  &
  \real^i\fakebar^j\fake^k  &
  \fake^i\realbar^j\real^k  &
  \fake^i\realbar^j\fake^k  &
  \fake^i\fakebar^j\real^k  &
  \fake^i\fakebar^j\fake^k  \\
  \real^i\realbar^j\realbar^k  &
  \real^i\realbar^j\fakebar^k  &
  \real^i\fakebar^j\realbar^k  &
  \real^i\fakebar^j\fakebar^k  &
  \fake^i\realbar^j\realbar^k  &
  \fake^i\realbar^j\fakebar^k  &
  \fake^i\fakebar^j\realbar^k  &
  \fake^i\fakebar^j\fakebar^k  \\
  \realbar^i\real^j\real^k  &
  \realbar^i\real^j\fake^k  &
  \realbar^i\fake^j\real^k  &
  \realbar^i\fake^j\fake^k  &
  \fakebar^i\real^j\real^k  &
  \fakebar^i\real^j\fake^k  &
  \fakebar^i\fake^j\real^k  &
  \fakebar^i\fake^j\fakebar^k  \\
  \realbar^i\real^j\realbar^k  &
  \realbar^i\real^j\fakebar^k  &
  \realbar^i\fake^j\realbar^k  &
  \realbar^i\fake^j\fakebar^k  &
  \fakebar^i\real^j\realbar^k  &
  \fakebar^i\real^j\fakebar^k  &
  \fakebar^i\fake^j\realbar^k  &
  \fakebar^i\fake^j\fakebar^k  \\
  \realbar^i\realbar^j\real^k  &
  \realbar^i\realbar^j\fake^k  &
  \realbar^i\fakebar^j\real^k  &
  \realbar^i\fakebar^j\fake^k  &
  \fakebar^i\realbar^j\real^k  &
  \fakebar^i\realbar^j\fake^k  &
  \fakebar^i\fakebar^j\real^k  &
  \fakebar^i\fakebar^j\fake^k  \\
  \realbar^i\realbar^j\realbar^k  &
  \realbar^i\realbar^j\fakebar^k  &
  \realbar^i\fakebar^j\realbar^k  &
  \realbar^i\fakebar^j\fakebar^k  &
  \fakebar^i\realbar^j\realbar^k  &
  \fakebar^i\realbar^j\fakebar^k  &
  \fakebar^i\fakebar^j\realbar^k  &
  \fakebar^i\fakebar^j\fakebar^k  
  \end{pmatrix} 
\end{align}
and we can solve for the inverse.  
We are only interested in the components with at least one
fake lepton, thus we construct the matrix $\mathbf{W}$ such that:
\begin{equation}
\mathbf{W} = 
\begin{pmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}
\end{equation}
Furthermore, the vector 
\begin{equation}
(N^{ijk})^T=\begin{pmatrix} 
  n_{TTT}^{ijk}&
  n_{TTL}^{ijk}&
  n_{TLT}^{ijk}&
  n_{TLL}^{ijk}&
  n_{LTT}^{ijk}&
  n_{LTL}^{ijk}&
  n_{LLT}^{ijk}&
  n_{LLL}^{ijk}
  \end{pmatrix}
\end{equation}
In this case, there is only one configuration that gives 
three tight leptons thus, the matrix $\mathbf{M}$ is constructed
to have be an $8x8$ matrix with 1 in the first element and 
all other elements being zero. This gives 

$(T^{ijk})^T=\begin{pmatrix} 
  \hat{f}_{TTT}^{ijk}& 0 & 0 & 0 & 0 & 0 & 0 & 0 
  \end{pmatrix}$
Putting everything together, we can solve for the estimated
number of events with three tight leptons 
coming from three leptons events with at least one fake lepton
with three leptons in bins $i$,$j$, and $k$:
\begin{align}
\begin{split}
\label{eq:mxm_threeleptons}
\hat{f}^{ijk}_{TTT} = ~& w_{TTT}(i,j,k)~n^{ijk}_{TTT}  \\
   &+(w_{TTL}(i,j,k)~n^{ijk}_{TTL} + j\leftrightarrow k + i \leftrightarrow k)\\
   &+(w_{LLT}(i,j,k)~n^{ijk}_{LLT} + j\leftrightarrow k + i \leftrightarrow k) \\
   &+w_{LLL}(i,k,j)~n^{ijk}_{LLL}
\end{split}
\end{align}
where the terms like $j\leftrightarrow k$ are intended to indicated
a copy of the first term in parentheses but with the indices 
switched as shown. Each term has a $w$ function that is a function
of the three lepton indices. These are the weights
extracted by the method and they end up taking a simple form:
\begin{equation}
\label{eq:mxm_wttt}
w_{TTT}(i,j,k) = 
-\frac{\real^i\fakebar^i}{\real^i-\fake^i}
\frac{\real^j\fakebar^j}{\real^j-\fake^j}
\frac{\real^k\fakebar^k}{\real^k-\fake^k}
\end{equation}
\begin{equation}
\label{eq:mxm_wttl}
w_{TTL}(i,j,k) = 
\frac{\real^i\fakebar^i}{\real^i-\fake^i}
\frac{\real^j\fakebar^j}{\real^j-\fake^j}
\frac{\real^k\fake^k}{\real^k-\fake^k}
\end{equation}
\begin{equation}
\label{eq:mxm_wllt}
w_{LLT}(i,j,k) =  
- \frac{\real^i\fake^i}{\real^i-\fake^i}
\frac{\real^j\fake^j}{\real^j-\fake^j}
\frac{\real^k\fakebar^k}{\real^k-\fake^k}
\end{equation}
\begin{equation}
\label{eq:mxm_wlll}
w_{LLL}(i,j,k) =  
\frac{\real^i\fake^i}{\real^i-\fake^i}
\frac{\real^j\fake^j}{\real^j-\fake^j}
\frac{\real^k\fake^k}{\real^k-\fake^k}
\end{equation}
One can see that for the case of zero or two loose leptons present, 
the magnitude of the weights are always negative (as long
as $\real > \fake$), while the for one and three loose leptons 
present, the magnitude is positive. As with the single
lepton case this is not of a concern as long as we look only 
take seriously the final expectation and this remains positive.
However, it might cause some concern to see that 
the magnitude of these weights decrease the more loose leptons 
are present, thus the highest magnitude weight
will in general be $w(i,j,k)_{TTT}$, which is negative!
Fortunately, in the sum this is balanced by the number of 
leptons observed, which tends to have the opposite trend.
As a result, it is those terms with exactly one loose lepton
observed that end up dominating the entire calculation, which
has a positive weight. The generalized matrix method has been 
checked using the rates evaluated in \sec\ref{} at the pre-selection stage
and can be seen in \fig\ref{fig:mxm_components}.
From this it is clear that the TTL 
term (which also includes the TLT and LTT terms) 
dominates the calculation,
though the effects of the negative weights, in particular from the TTT
term, can clearly be seen in the sum. Also, notice that the contribution
from terms without three initial leptons is small. This includes contributions
with greater than three leptons and can be expalined by the rarity of
processes that produce such high lepton multiplicities.
Thus one could arrive at a good approximation to the full method
by just using \eqn\eqref{eq:mxm_threeleptons} along with just the
weights in \eqn\eqref{eq:mxm_wttt} and \eqref{eq:mxm_wttl}.
\begin{figure}
\centering
\includegraphics[width=.45\columnwidth]{figures/CompareMxMComponents/ChargeSameSign_PreselCustomRates_Mar19/png/LeadingLeptonPt.png}
\includegraphics[width=.45\columnwidth]{figures/CompareMxMComponents/ChargeSameSign_PreselCustomRates_Mar19/png/SubleadingLeptonPt.png}
\includegraphics[width=.45\columnwidth]{figures/CompareMxMComponents/ChargeSameSign_PreselCustomRates_Mar19/png/MinimumLeptonPt.png}
\includegraphics[width=.45\columnwidth]{figures/CompareMxMComponents/ChargeSameSign_PreselCustomRates_Mar19/png/MET_Et_STVF.png}
\caption{Fake background estimate at preselection broken
into tight and loose lepton configuration components for the 
leading (top left), subleading (top right), and minimum lepton \pt~(bottom left)
as well as the \met~(bottom right). The three lepton TTT (orange dots),
TTL (pink dots), TLL (blue dots), and LLL (yellow dots) components
are shown along with any other components (green dots) such as those
with four leptons initally.  The sum of all these components is also
shown (black line). (what if I showed the absolute value of these weights?)}
\label{fig:mxm_components}
\end{figure}


In the analysis, a specialized code is used to evaluate the 
Generalized Matrix Method
on all possible combinations of input and output leptons and checks
to see which leptons pass the final selection. 
It uses the on-the-fly
weighting method described above and uses a tensor
formulation that improves the computational efficiency of the method.
This is also used described in \cite{Gillam:2014xua}.
Uncertainties are calculated by propogating through 
the uncertainties on the rates. 
Using the standard propogation of uncertaintity, this relies
on the derivative of the expectation with respect to the rates.
Fortunately, this can be calculated in a straightforward way,
though it will not be described here.
Correlations between different bins are assumed to be negligible and 
are ignored.  However, since the method relies on calculating multiple
weights from the same event, there is a correlation in the uncertainty
if these weights end up falling in the same bin. To handle this 
correlation the uncertainty for these weights are added linearly 
as opposed to in quadrature when extracting the final uncertainty 
on the method. The impact of this is seen to mostly negligible
with respect to treating them as completely uncorrelated.

\subsubsection{Rate Determination}

The Generalized Matrix Method relies on being able to determine
the real and fake rates to be used as inputs to the method.
This is usually done by looking into control regions
which are designed to be enhanced in sources of real and fake leptons.
It is important to note that we can never know with certainty 
whether a lepton is real or fake. Instead we must be clever enough
to find leptons that we are confident are of the appropriate type.
One clever trick is to use a method called the tag-and-probe method
to better identify real or fake leptons in the control regions;
it will be described shortly.
Once we have obtained our two separate collections of leptons,
one we believe to be rich in real leptons and the other in fake leptons,
we can use these leptons to extract the real and fake rates, respectively.
The real rate, $\real^i$, in category (or bin) $i$,
is simply defined as the ratio of tight candidate real leptons
over the number of tight plus loose candidate real leptons:
\begin{equation}
\label{eq:real_rate}
\real^i = \frac{r_T^i}{r_T^i+r_L^i}
\end{equation}
where $r_T^i$ and $r_L^i$ are the number of tight and loose candidate
real leptons in category $i$, to be 
distinguished from the $n_T^i$ and $n_L^i$ which
are the number of candidate and loose real leptons in the signal regions
and whose origin is unknown.
Similarly, the fake rate, $\fake^i$, in category $i$ is,
is defined as the ratio of tight candidate fake leptons over
the number of tight plus loose candidate fake leptons:
\begin{equation}
\label{eq:fake_rate}
\fake^i = \frac{f_T^i}{f_T^i+f_L^i}
\end{equation}
where $f_T^i$ and $f_L^i$ are the number of tight and loose candidate
fake leptons in category $i$.

The real and fake rates are not universally the same for all leptons, 
and in fact can vary strongly. Thus, the choice of categories, $i$, is
an important one. The rates are usually split by lepton
flavor and also in bins of at least one kinematic quantity.
The splitting of the categories by flavor is 
very important as the rates are 
typically very different for electrons and muons. 
This is in part because
the loose and tight selections are usually chosen to be different
by necessity.
The tight selections are the same as in \sec\ref{sec:www_object_selection}
for both electrons and muons.  The loose selections, however,
are similar to the tight selection except that
the isolation requirements are removed and the object quality 
classification is loosened for electrons.
Another reason why splitting the categories into lepton flavors
is important is that 
the control regions which are enhanced in real and fake sources
of leptons are typically different for electrons and muons.
Thus, we choose to evaluate the rates separately for both.


The rates also tend to vary as a function of the lepton kinematics.
In particular, both the real and fake rates tend to increase
as a function of the lepton $\pt$.  Thus, we further divide the electron
and muon categories into subcategories of mutually exclusive bins of
$\pt$. The number of bins and the bin edges are determined 
to best capture the shape while also mainiting adequate statistics
in each category. In practrice it is usually not possible to subdivide
the \pt~by more than a 3-5 bins. For the same reason, while
the rates also surely vary according to other kinematic criteria, 
like $\eta$, it is usually not possible to subdivide in more than
one kinematic variable and still have good statistics.


The control regions are chosen so as to be dominated by a single 
physics process.  For determining the real rates, the 
control region is chosen to be enchanced in $Z\rightarrow ll$
while the control region for determining the fake rates is
chosen to be enhanced in 
$W\rightarrow l\nu + \textrm{Jets}$.
The reason for this choice is to allow for the application of the
tag-and-probe method, which uses one well defined lepton, the
``tag'', to identify the process, and another lepton, the ``probe'',
as the lepton under study. Both of these control regions
have at least one lepton object. 

\begin{figure}[ht!]
\centering
\subfigure{
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/hPtElectronZBosonloosecut_total_new.eps}
}
\centering
\subfigure{
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/hPtMuonZBosonloosecut_total_new.eps}
}
\vspace{-10mm}\caption{Invariant mass distribution of two opposite charge and same flavor di-lepton invariant mass electrons (left) and muons (right). Update figures!!}
\label{fig:realEff_CRs}
\end{figure}

\begin{figure}[ht!]
\centering
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeTightElectronPt_histratio.png}
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeTightMuonPt_histratio.png}
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeElectronPt_histratio.png}
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeMuonPt_histratio.png}
\caption{Probe lepton \pt\ distributions in SFOS tag and probe control regions used to derive real rates.  Electron (left) and muon (right) are shown
when the probe lepton is either tight (top) or no additional selection (besides the pre-selection) is required (bottom)}
\label{fig:realEff_CRsPt}
\end{figure}

In the control region enhanced
in $Z\rightarrow ll$, if one well reconstructed 
tag lepton passing the tight selection is found then the presence
of an additional lepton will almost certaintly be the other real
lepton from the $Z$ decay. Thus, this second ``probe''
lepton, which can pass either the loose or tight selection
requirement is our candidate real lepton.
Note that if the probe lepton also passes the tight selection
then it could also be used as a tag. In fact, ignoring
this possibility can introduce a bias. Thus, we consider both 
leptons as tag or probe and candidates.
The control region is formed by a selection where 
the tag lepton passes the same single lepton triggers and trigger
matching requirements as in \sec\ref{sec:www_event_selection}
plus an additional probe lepton that forms an SFOS pair with the
tag that has a di-lepton mass within 10~\GeV of the \z-mass.
Two control regions are formed: one from $e^{+}e^{-}$ tag-probe
pairs for determining the electron real rates and another
from $\mu^{+}\mu^{-}$ tag-probe pairs for determining the muon
real rates. The \z-peak in the 
di-lepton invariant mass distribution for the two control regions
are shown in \fig\ref{fig:realEff_CRs} comparing the data
to the model.
Since the rates are also determined as a function of the lepton
\pt, the lepton \pt~distributions are shown in 
\fig\ref{fig:realEff_CRsPt}
for the data as well as the expectation separately for electrons
and muons and also split based on whether the probe leptons
pass just the tight selection 
(the top row of \fig\ref{fig:realEff_CRsPt})
or both the loose and tight selections
(the bottom row of \fig\ref{fig:realEff_CRsPt}).
The expectation clearly agrees well with the expectation, which is dominated
by the $Z\rightarrow ll$ process, as expected. The ratio of the 
candidate real leptons passing just the tight selection 
over those passing the loose and tight selections 
determines the real rate according to \eqn\eqref{eq:real_rate}.
The real rates are shown separately for electrons and muons 
in \fig\ref{fig:realEff} after adjusting to a coarser binning
to improve the statistics. 
It is interesting to note that the real rates
are uniformly lower for electrons than for muons, but both follow
the same trend of increasing as a function of the lepton \pt, 
and are relatively high even for the lowest value of 81\%.
The rates are calculated both using 
the data or the MC exclusively and the difference
is taken as a systematic uncertainty on the nominal estimate
from the data. 
The rates and the systematic uncertainties
are summarized for electrons
in \tab\ref{tab:realEff_El} and for muons in \tab\ref{tab:realEff_Mu}.




\begin{figure}[ht!]
\centering
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/Efficiencies/ElectronRealRates.png}
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/Efficiencies/MuonRealRates.png}
\caption{Real lepton efficiency as a function of \pt\ and measured in data (red) and MC (blue) for electrons (left) and muons (right).}
\label{fig:realEff}
\end{figure}


%\tabcolsep=0.11cm
\begin{table}[ht!]
\centering
\input{tables/ElectronRealRates.tex}
\caption{Measured real efficiencies for electrons including statistical and systematic absolute uncertainties. 
Systematic is calculated by taking the difference
between the efficiencies measured in data and MC.  The efficiency measured in data is used as the nominal central value.
} 
\label{tab:realEff_El}
\end{table} 

%\tabcolsep=0.11cm
\begin{table}[ht!]
\centering
\input{tables/MuonRealRates.tex}
\caption{Measured real efficiencies for muons including statistical and systematic absolute uncertainties.
Systematic is calculated by taking the difference
between the efficiencies measured in data and MC.  The efficiency measured in data is used as the nominal central value.
} 
\label{tab:realEff_Mu}
\end{table} 


On the other hand, in the 
$W\rightarrow l\nu + \textrm{Jets}$ control region there
is only one real lepton being produced by the process.
If a well reconstructed tag lepton passing the tight selection
is found in this control 
region it is most likely coming from the $W$ decay.
In this case, if we measure a second ``probe'' lepton it is most likely
a jet faking a lepton. Thus, we have found a candidate fake lepton.





is that both control regions
have at least one lepton plus another obje




\tabcolsep=0.11cm
\begin{table}[ph!]
\begin{center}
\small{
    \begin{tabular}{lc}
%      \hline
%      Cut            & Value/description \\
      \hline
      \hline
      \multicolumn{2}{c}{\textbf{Preselected electron}}\\
      \hline
      Algorithm      & Central Electrons (author is 1 or 3)\\
      \hline
      Acceptance     & $\pt > 10\,\GeV, |\eta| < 2.47$ excluding crack region \\
      \hline
      Quality & \texttt{Medium++} \\
%      \hline
%      Further cuts & not touching dead OTX region\\
      \hline
      Impact parameter & $|d_0/\sigma(d_0)| < 3.0$\\ 
      & $|z_0 \cdot sin(\theta)|<$ 0.5 mm \\
      \hline
      $e$-$e$ isolation             & $\Delta{}R(e,e)>0.2$ \\
      \hline
      $e$-$\mu$ isolation      & $\Delta{}R(e,\mu)>0.2$ \\
      \hline
      \multicolumn{2}{c}{\textbf{Signal electron}}\\
      \hline
      Quality & \texttt{Tight++} \\
%      \hline
%      Track   & with match \\
      \hline
      Track isolation   & \pt cone20/\pt $<0.04$\\
      \hline
      Calorimeter isolation & \ET cone20/\ET$<0.10$\\% for \pt$>20$\GeV\\
      					  % & \ET cone20/\ET$<0.07$ for \pt$<20$\GeV\\
     \hline
     \hline
\end{tabular}
}
\end{center}
\caption{Summary of the electron selection criteria used for the global matrix method. The signal requirements defined in Section~\ref{sec:Object_selection} are applied on top of the lepton pre-selection.}
\label{tab:eledef}
\end{table}

\tabcolsep=0.11cm
\begin{table}[ph!]
  \begin{center}%\renewcommand\arraystretch{1.2}
  \small{
    \begin{tabular}{lc}
%      \hline
 %     Cut            & Value/description \\
      \hline
      \hline
      \multicolumn{2}{c}{\textbf{Preselected muon}}\\
      \hline
      Algorithm      & STACO combined \\
      \hline
      Acceptance     & $\pt > 10\,\GeV, |\eta| < 2.5$ \\
      \hline
      Quality        & Tight    \\
      \hline
      Inner detector track quality & MCP ID Hits selection\\
      \hline
            Impact parameter & $|d_0/\sigma(d_0)| < 3.0$\\ 
      & $|z_0 \cdot sin(\theta)|<$ 0.5 mm \\
      \hline
      $\mu$-$\mu$ isolation             & $\Delta{}R(\mu,\mu)>0.2$ \\
      \hline
      \multicolumn{2}{c}{\textbf{Signal muon}}\\
      \hline
      Track isolation   & \pt cone20/\pt $<3.0$\\
      \hline
      Calorimeter isolation & \ET cone20/\ET $<0.10$\\% for \pt$>20$\GeV\\
      						%& \ET cone20/\ET $<0.07$ for \pt$<20$\GeV\\
      \hline
      \hline
    \end{tabular}
    }
  \end{center}
   \caption{Summary of the muon selection criteria used for the global matrix method. The signal requirements defined in Section~\ref{sec:Object_selection} are applied on top of the lepton pre-selection.} 
    \label{tab:muondef}
\end{table}



The efficiencies for real preselected leptons to pass the tight requirements are measured in data as a function of the lepton $\pt$. The measurement is performed in data samples enriched with real leptons from $Z\rightarrow l^+l^-$ decay with a standard tag-and-probe method. The tag passes all signal lepton selections and is trigger matched, while the requirement imposed to the probe is to satisfy only the lepton pre-selection cuts. Their invariant mass has to be within $Z$-mass window: $m_{ll}\in[80, 100]$~\GeV{}. If both leptons satisfy the tag requirements, they are alternatively considered as the tag in order to avoid any bias introduced by its selection. The invariant mass for two opposite sign same-flavor leptons is illustrated in Fig. \ref{fig:realEff_CRs}.

The $\pt$ distributions for both the number of probes passing the signal requirements, $n^{\mathrm{Tight}}$, and the total number of probes, $n$, are shown separately in the electron and muon control regions used to derive the rates in Figure~\ref{fig:realEff_CRsPt}.
The efficiency, $\varepsilon_i$, is calculated in each $\pt$ bin, $i$, by taking the ratio of $n_{i}^{\mathrm{Tight}}$ over $n_i$. That is,
\begin{align*}
%\varepsilon_i=\frac{n_T^{\mathrm{probe}}}{n^{\mathrm{probe}}}
\varepsilon_i=\frac{n_{i}^{\mathrm{Tight}}}{n_{i}}
\end{align*}
The final binning of the efficiency is chosen to be coarse enough
to have good statistics in the ratio while also preserving shape information as a function
of $\pt$. 
The final efficiencies determined using both data and MC 
can be seen in Fig. \ref{fig:realEff}.

Two sources of systematic uncertainties are taken into account. Firstly, the measurement may be affected by the selection of $20$~\GeV\ $Z$-mass window. It has been thus varied by $5$~\GeV\ and the final effect has been proved to be negligible. Secondly, the measurement is done in Drell-Yan data without any  specific treatment of the other background. Therefore, the difference between the efficiencies measured in data and MC is taken as a systematic.  A summary of the rates measured in
data and MC used to compute the systematic uncertainties are shown for electrons
in Table~\ref{table:realEff_El} and for Muons in Table~\ref{table:realEff_Mu}.

\begin{figure}[h!]
\centering
\subfigure{
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/hPtElectronZBosonloosecut_total_new.eps}
}
\centering
\subfigure{
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/hPtMuonZBosonloosecut_total_new.eps}
}
\vspace{-10mm}\caption{Invariant mass distribution of two opposite charge and same flavor di-lepton invariant mass electrons (left) and muons (right).}
\label{fig:realEff_CRs}
\end{figure}


\begin{figure}[h!]
\centering
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeTightElectronPt_histratio.png}
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeTightMuonPt_histratio.png}
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeElectronPt_histratio.png}
\includegraphics[width=0.4\columnwidth]{figures/fakes_bkg/CRs/RealTP/ProbeMuonPt_histratio.png}
\caption{Probe lepton \pt\ distributions in SFOS tag and probe control regions used to derive real rates.  Electron (left) and muon (right) are shown
when the probe lepton is either tight (top) or no additional selection (besides the pre-selection) is required (bottom)}
\label{fig:realEff_CRsPt}
\end{figure}


\begin{figure}[h!]
\centering
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/Efficiencies/ElectronRealRates.png}
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/Efficiencies/MuonRealRates.png}
\caption{Real lepton efficiency as a function of \pt\ and measured in data (red) and MC (blue) for electrons (left) and muons (right).}
\label{fig:realEff}
\end{figure}

\clearpage

%\tabcolsep=0.11cm
\begin{table}[h!]
\centering
\input{tables/ElectronRealRates.tex}
\caption{Measured real efficiencies for electrons including statistical and systematic absolute uncertainties. 
Systematic is calculated by taking the difference
between the efficiencies measured in data and MC.  The efficiency measured in data is used as the nominal central value.
} 
\label{table:realEff_El}
\end{table} 

%\tabcolsep=0.11cm
\begin{table}[h!]
\centering
\input{tables/MuonRealRates.tex}
\caption{Measured real efficiencies for muons including statistical and systematic absolute uncertainties.
Systematic is calculated by taking the difference
between the efficiencies measured in data and MC.  The efficiency measured in data is used as the nominal central value.
} 
\label{table:realEff_Mu}
\end{table} 


\clearpage

\subsubsection{Fake lepton efficiency}

The fake efficiency represents the probability that a fake lepton satisfying the preselected criteria passes also the signal requirements. 
The measurement, performed separately for each $\pt$ bin, $i$, is performed in fake-enriched samples by looking at the number of probe leptons in data 
passing pre-selection, $n_i$, and comparing to the number which only pass also the tight
selection, $n^{Tight}_i$. Contamination from real leptons, $n^{\mathrm{Real}}_i$ and $n^{\mathrm{Tight}, \mathrm{Real}}_i$, 
and from photon converted leptons, $n^{\mathrm{PC}}_i$ and $n^{\mathrm{Tight},\mathrm{PC}}_i$, 
is corrected using MC by subtracting from the totals.  The rate is then determined as follows:
%\begin{align*}
\begin{equation}
\zeta_i=\frac{n^{\mathrm{Tight}}_i-n^{\mathrm{Tight},\mathrm{Real}}_i-n^{\mathrm{Tight},\mathrm{PC}}_i} {n_i -n^{\mathrm{Real}}_i -n^{\mathrm{PC}}_i }
\label{eq:fakerate}
\end{equation}
%\end{align*}
Since the rates depend on the fake lepton origin, the derivation is done separately for electrons and muons.     

The classification of leptons in MC as being either real or from photon conversion is performed on an event-by-event basis at truth level using the MCTruthClassifier tool~\cite{MCtruthclassifier:twiki}.  
Since this is a di-lepton control region, the majority of events with a real lepton
tag and a probe lepton due to photon conversion comes from the $W\gamma$ process where the photon converted lepton is an electron.
As expected, the number of probe muons coming from photon conversion are observed to be negligible.

Efficiencies are measured from a data set enriched with one tight lepton that passes the signal lepton selections with \pt$>40$~\GeV\ and 
one fake candidate satisfying only the pre-selection criteria defined in tables~\ref{tab:eledef} and~\ref{tab:muondef}. Events with additional loose or tight leptons are rejected. 
The QCD background may also enter these control regions, especially in low \met\ . Therefore, an additional \met$>10$~\GeV\ requirement is introduced. 
In order to reduce the contamination from real processes like $t\bar{t}$, $WW$ and $Z$, the two leptons are required to have the same sign.
Finally, the control regions are split based on the flavor of the tag and probe leptons.  The muon rates are determined in the region
with two muons while the electron rates are determined in the region with a muon tag and an electron probe.  The choice of a muon tag 
in the region used to derive the electron rates is particularly important since allowing electron tags have a large contamination from $Z$ backgrounds.
This is true even after the same-sign requirement because of charge mis-identification.  
The charge mis-identification rate for muons is negligible
and so allows one to use the muon-muon control region for the muon rates, which has the least contamination.
This behavior can be seen in the distributions of probe muon transverse momentum in the same-sign muon-muon tag-and-probe control region used to derive
the muon fake rates shown in Fig.~\ref{fig:fakeEff_CRs_muon} while
the distributions of probe electron transverse momentum are shown in the same-sign electron-muon tag-and-probe control region used to derive
the electron fake rates shown in Fig.~\ref{fig:fakeEff_CRs_electron}.
The control regions for both electrons and muons are further split based on the number of b-tagged jets in the event, 
which has an effect on the source of the fake leptons.  In particular, requiring b-tagged jets increases the fraction
of fake leptons coming from heavy flavor. Two different sets of control regions were ultimately considered, those
with at least one b-tagged jet and those without any requirement on the presence of b-tagged jets.  The region
with at least one b-tagged jet ($N_{b-jet} > 0$) is used as the central value since it contains more heavy flavor contributions
and so compares better with the signal regions, as described later in Section~\ref{sec:fakecomposition}.  The other is used 
to determine a systematic on the composition, described later.  


A detailed breakdown of the numbers used to compute the fake rates are shown in Appendix~\ref{sec:appendix_fakebg}.
%would it be useful to show the other di-lepton control regions in an appendix?

Three systematic uncertainties are considered. First, the subtraction of the processes with 
two real leptons ($t\bar{t}V$, $VV$ and $VVV$) using MC prediction introduced an uncertainty on 
their cross-sections. This effect is estimated by varying the MC normalization by $\pm 20$\%.  %should rerun with 5%
We refer to this is as the 'correlated' systematic uncertainty.
Second, given that the extraction regions and the signal regions have different kinematic selections, 
the fake leptons of different origin dominate. This kinematic dependence of fake efficiencies has been estimated 
by modifying the requirements of the sample used for the measurement. In particular, the cut thresholds 
on the $E_{T}^{Miss}$ and tag lepton $\pt$ used
for determining the di-lepton control regions are varied. The $E_{T}^{Miss}$ threshold is 
varied in 5~GeV steps scanning a range of $\pm 10$~GeV around the nominal
threshold of $E_{T}^{Miss} > 10$~GeV while the $\pt$ threshold is varied in 5~GeV steps in a range of $\pm 20$~GeV 
around the nominal threshold of $\pt > 40$~GeV.  When varying the $E_{T}^{Miss}$ cut, the $\pt$ cut
is kept at the nominal threshold and vise-versa. This is referred to as the 'uncorrelated' systematic.
These are determined separately for electrons and muons, since they use different control regions. The 'uncorrelated' and
'correlated' systematics for electrons and muons are then combined together by adding in quadrature on an event-by-event basis.
As a result the uncertainty is presented as a single systematic uncertainty on the fake electron
contribution and a separate single systematic on the fake muon contribution.
The third and final systematic contribution comes from the choice of control region, based on the number of b-tagged
jets, as described earlier.  The nominal control regions for both the electron and muon cases is when 
there is at least one b-tagged jet present.  The difference between the rates for the nominal case
and the region where no requirement is placed on the presence of b-tagged jets is chosen as a systematic.
We have determined that the difference in the composition in these two regions adequately covers the difference
in composition that may be present due to the extrapolation from the control regions to the signal regions. This is 
discussed in more detail in Section~\ref{sec:fakecomposition}.  Another set of control regions was studied
which vetoes any b-tagged jets, but this was observed to give a very large difference in composition which is 
probably too conservative of an estimate to be used as a reasonable systematic.
The rates along with the statistical and systematic uncertainties are summarized in Fig.~\ref{fig:fakeEff} 
as well as in Tables \ref{table:fakeEff_El} and \ref{table:fakeEff_Mu}.
The final binning of the efficiency is chosen to be coarse enough
to have good statistics in the ratio while also preserving shape information as a function
of $\pt$. 


%\begin{figure}[h!]
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/CR1N_probePt_all_total.eps}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/CR2N_probePt_all_total.eps}
%}\\ 
%\vspace{-14mm}
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/CR1N_probePt_tight_total.eps}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/CR2N_probePt_tight_total.eps}
%}
%\vspace{-10mm}\caption{Transverse momentum distributions \pt\ of probe electron (left) and muon (right) in the control regions. The probe passes pre-selection (top) and signal (bottom) criteria.}
%\label{fig:fakeEff_CRs}
%\end{figure}


\begin{figure}[h!]
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/NoStack/ProbeTightMuonPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/NoStack/ProbeTightMuonPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/NoStack/ProbeTightMuonPtBJetGt0.eps}
}
%\vspace{-1mm}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/NoStack/ProbeLooseORTightMuonPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/NoStack/ProbeLooseORTightMuonPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/NoStack/ProbeLooseORTightMuonPtBJetGt0.eps}
}
\vspace{-10mm}\caption{Transverse momentum distributions \pt\ of tight probe muons (top) and loose OR tight probe muons (bottom) passing signal selection criteria in the control Same-Sign $\mu-\mu$ control region without any additional requirement on $b$-jets in the event (left) and at least one $b$-jet (right). 
The amount observed in data (black points) corresponds to $n$ (bottom) and $n_{\textrm{Tight}}$ (top) in Eq.~\ref{eq:fakerate}. 
Meanwhile, the contribution determined in MC to come from real leptons (blue line) and from photon conversion (red line) are shown 
separately; they are not stacked. The real lepton contribution corresponds to 
$n_{\textrm{Tight}}^{\textrm{Real}}$ (top) and $n^{\textrm{Real}}$ (bottom) and the photon conversion 
contribution corresponds to $n_{\textrm{Tight}}^{\textrm{PC}}$ (top) and $n^{\textrm{PC}}$ (bottom) in Eq.~\ref{eq:fakerate}. The photon conversion is 
observed to be negligible for muons.  }
\label{fig:fakeEff_CRs_muon}
\end{figure}

\begin{figure}[h!]
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/NoStack/ProbeTightElectronPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/NoStack/ProbeTightElectronPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/NoStack/ProbeTightElectronPtBJetGt0.eps}
}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/NoStack/ProbeLooseORTightElectronPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/NoStack/ProbeLooseORTightElectronPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/NoStack/ProbeLooseORTightElectronPtBJetGt0.eps}
}
%\vspace{-1mm}
\vspace{-10mm}\caption{Transverse momentum distributions \pt\ of tight probe electron (top) and loose or tight probe electrons (bottom) passing signal selection criteria in the Same-Sign $e-\mu$ control region without any additional requirement on $b$-jets in the event (left) and at least one $b$-jet (right).
The amount observed in data (black points) corresponds to $n$ (bottom) and $n_{\textrm{Tight}}$ (top) in Eq.~\ref{eq:fakerate}. 
Meanwhile, the contribution determined in MC to come from real leptons (blue line) and from photon conversion (red line) are shown 
separately; they are not stacked. The real lepton contribution corresponds to 
$n_{\textrm{Tight}}^{\textrm{Real}}$ (top) and $n^{\textrm{Real}}$ (bottom) and the photon conversion 
contribution corresponds to $n_{\textrm{Tight}}^{\textrm{PC}}$ (top) and $n^{\textrm{PC}}$ (bottom) in Eq.~\ref{eq:fakerate}.  }
\label{fig:fakeEff_CRs_electron}
\end{figure}






\begin{figure}[ht!]
\centering
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/Efficiencies/ElectronFakeRates.png}
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/Efficiencies/MuonFakeRates.png}
%\vspace{-10mm}
\caption{Distributions of the electron (left) and muon (right) fake rates as a function of \pt\ extracted in the control regions for three different selections: without any additional requirement on $b$-jets in the event and at least one $b$-jet.}
\label{fig:fakeEff}
\end{figure}




%\tabcolsep=0.1cm
%\begin{table}
%\centering
%\resizebox{0.8\textwidth}{!}{
%\begin{tabular}{l|c|c|c|c|c|c|c} 
%\hline
%\multicolumn{4}{c}{Electrons} &\multicolumn{4}{c}{Muons}\\ \hline
%\pt\ region & Fake eff. & $\sigma_{\mathrm{stat}}$ & $\sigma_{\mathrm{syst}}$ &\pt\ region & Fake eff. & $\sigma_{\mathrm{stat}}$ & $\sigma_{\mathrm{syst}}$ \\\hline
%$\pt \in [10, 15]$ \GeV\ & $0.$ & $0.$ & $0.$ 
%& $\pt \in [10, 15]$ \GeV\ & $0.$ & $0.$ & $0.$ \\
%$\pt \in [15, 30]$ \GeV\ & $0.$ & $0.$ & $0.$
%& $\pt \in [15, 20]$ \GeV\ & $0.$ & $0.$ & $0.$ \\
%$\pt\in [30, 50]$ \GeV\ & $0.$ & $0.$ & $0.$
%& $\pt\in [20, 40]$ \GeV\ & $0.$ & $0.$ & $0.$ \\
%$\pt > 50$ \GeV\ & $0.$ & $0.$ & $0.$
%& $\pt > 40$ \GeV\ & $0.$ & $0.$ & $0.$ \\
%\hline
%\end{tabular}  }
%\caption{Measured fake efficiencies for electrons and muons including statistical and systematic absolute uncertainties.} 
%\label{table:fakeEff_All}
%\end{table} 

\begin{table}[h]
\centering
\input{tables/ElectronFakeRates.tex}
\caption{Measured fake efficiencies for electrons measured in three regions: with no additional requirements on the presence of $b$-jets and with at least one $b$-jet in a event. Statistical and systematic absolute uncertainties are also shown.} 
\label{table:fakeEff_El}
\end{table} 


\begin{table}[h]
\centering
\input{tables/MuonFakeRates.tex}
\caption{Measured fake efficiencies for muons measured in three regions: with no additional requirements on the presence of $b$-jets and with at least one $b$-jet in the event.  Statistical and systematic absolute uncertainties are also shown.} 
\label{table:fakeEff_Mu}
\end{table} 


\clearpage

\subsubsection{Study of the fake lepton composition}
\label{sec:fakecomposition}

The use of the generalized matrix method to determine the 
relies on the assumption that the 
fake rates derived in the di-lepton control regions may be extrapolated to the three lepton signal regions.  
The fake rate depends primarily on the source of the fake leptons, thus
one can check the validity of this assumption by looking at the composition of the
different fake lepton sources in the di-lepton control regions and comparing 
them to the
composition in the three lepton signal regions. 

The fake composition is investigated by classifying the MC events as a function of the origin of the fake leptons found in each event.  The MCTruthClassifier tool~\cite{MCtruthclassifier:twiki} is used
to identify the fake laptops origin as follows:

\begin{itemize}
\item Real - Prompt leptons
		\begin{itemize}
		\item \emph{IsoElectron} 
		\item \emph{IsoMuon}
		\item In $Z\gamma$ events classified as either \emph{UnknownElectron} or \emph{UnknownMuon} and parent of lepton is $\gamma$.
		\item In $Z\rightarrow\tau\tau$ events classified as either \emph{NonIsoElectron} or \emph{NonIsoMuon} and lepton has $\tau$ as parent.
		\end{itemize}
\item Heavy Flavor (HF) - Leptons from heavy flavor jets or heavy hadron decays
		\begin{itemize}
		\item \emph{NonIsoElectron} 
		\item \emph{NonIsoMuon}
		\end{itemize}
\item Light Flavor (LF) -  Leptons from light flavor jets
		\begin{itemize}
		\item \emph{Hadron} 
		\item \emph{Others}
		\item In $ZWW$ and $ZZZ$ events classified as either \emph{UnknownElectron} or \emph{UnknownMuon} and parent of lepton is either an up quark, down quark, or a gluon.
		\end{itemize}
\item Photon Conversion (PC)  - Leptons due to radiation
		\begin{itemize}
		\item \emph{BkgElectron} 
		\item \emph{BkgMuon}
		\end{itemize}

\end{itemize}

The composition is shown for electrons in the di-lepton control 
regions in Table~\ref{table:CompositionElectronCR} and in the event pre-selection and in region close to the signal regions in Table~\ref{table:CompositionElectronSR}.
First, one can see that the PC contribution is roughly half of the fake contribution
estimate using MC
in the control regions and in the region close to the signal regions. Since this is being estimated
using MC close to the signal regions, 
this component is subtracted out in order to remove any double counting
in the final estimate. Then, after subtraction,
if one compares the composition in the control regions
to the composition in the region close to the signal regions only for electrons, 
in particular after tight selection, one can see that 
the composition is similar for both, 
with about 50 to 75 \% coming from HF and the rest from LF.

For the muons, one can see the composition in the di-lepton control regions in 
Table~\ref{table:CompositionMuonCR} and in the event pre-selection
and region close to the signal regions in Table~\ref{table:CompositionMuonSR}. For the muons the PC
component is negligible, as expected, and there is no need for subtraction.
In this case, the composition is dominated by HF, contributing about 90\% with the
rest coming from LF.  This is true in the region close to the signal regions and in the control regions.

The differences observed in the composition between the inclusive $b-jet$ and $b-jet$ 
tagged di-lepton control regions is observed to be of a similar size
to the difference in the composition for the region close to the signal regions for both the electron 
and muon cases.
Thus, comparing the rates derived in the control regions using the two different
$b-jet$ criteria should take into account any differences in the composition due
to extrapolation. This is the motivation for choosing the difference in these two 
control regions as an additional systematic on the fake rates.

Using this study of the composition, we conclude that the composition appears to be
consistent between the control regions and the region close to the signal regions.  We have chosen 
a comparison of two different di-lepton control regions to be used a systematic
which should take into account any remaining differences in the composition.

It should be said that in the di-lepton control regions, 
the MC estimate strongly underestimates the amount observed
in data, presumably because of additional sources of fakes 
not modeled in our MC, such as from QCD. 
The difference in the estimates can be clearly seen in Figures~\ref{fig:fakeEff_CRs_muon_stacked}
and \ref{fig:fakeEff_CRs_electron_stacked} which show the stacked MC estimate from real, photon conversion,
heavy flavor and light flavor sources compared to data.
Thus, the composition estimates shown are only reliable 
if these additional sources would have a similar composition to the ones observed
in this study that we are able to model. This effectively 
puts a large uncertainty on the composition estimates observed in this study. Also,
because the additional sources are most likely dominated by QCD, the PC 
contribution to these sources should be small. Thus, the PC component before subtraction
is likely overstated as shown in 
Tables~\ref{table:CompositionElectronCR} 
and \ref{table:CompositionElectronSR}.
As discussed earlier, we subtract the PC
component from the data when obtaining the fake rate. This procedure then assumes
explicitly that all of the photon conversion contribution is modeled in MC and is 
small.


\begin{figure}[h!]
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Stacked/ProbeTightMuonPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Stacked/ProbeTightMuonPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Stacked/ProbeTightMuonPtBJetGt0.eps}
}
%\vspace{-1mm}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Stacked/ProbeLooseORTightMuonPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Stacked/ProbeLooseORTightMuonPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Stacked/ProbeLooseORTightMuonPtBJetGt0.eps}
}
\vspace{-10mm}\caption{Transverse momentum distributions \pt\ of tight probe muons (top) and loose OR tight probe muons (bottom) passing signal selection criteria in the control Same-Sign $\mu-\mu$ control region without any additional requirement on $b$-jets in the event (left) and at least one $b$-jet (right). 
The amount observed in data (black points) corresponds to $n$ (bottom) and $n_{\textrm{Tight}}$ (top) in Eq.~\ref{eq:fakerate}. 
Meanwhile, the contribution determined in MC to come from real leptons (blue), photon conversion (red), heavy flavor (green) and light
flavor (orange) are shown stacked on top of each other. 
The difference between the data and MC does not effect the data-driven
fake estimate but may have an impact on the composition estimate.
}
\label{fig:fakeEff_CRs_muon_stacked}
\end{figure}

\begin{figure}[h!]
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Stacked/ProbeTightElectronPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Stacked/ProbeTightElectronPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Stacked/ProbeTightElectronPtBJetGt0.eps}
}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Stacked/ProbeLooseORTightElectronPt.eps}
}
%\centering
%\subfigure{
%\includegraphics[width=0.3\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Stacked/ProbeLooseORTightElectronPtBJetEq0.eps}
%}
\centering
\subfigure{
\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Stacked/ProbeLooseORTightElectronPtBJetGt0.eps}
}
%\vspace{-1mm}
\vspace{-10mm}\caption{Transverse momentum distributions \pt\ of tight probe electron (top) and loose or tight probe electrons (bottom) passing signal selection criteria in the Same-Sign $e-\mu$ control region without any additional requirement on $b$-jets in the event (left) and at least one $b$-jet (right).
The amount observed in data (black points) corresponds to $n$ (bottom) and $n_{\textrm{Tight}}$ (top) in Eq.~\ref{eq:fakerate}. 
Meanwhile, the contribution determined in MC to come from real leptons (blue), photon conversion (red), heavy flavor (green) and light
flavor (orange) are shown stacked on top of each other.
The difference between the data and MC does not effect the data-driven
fake estimate but may have an impact on the composition estimate.
}
\label{fig:fakeEff_CRs_electron_stacked}
\end{figure}

%%%%%%%%%%%scaled

%\begin{figure}[h!]
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Scaled/coarse/ProbeTightMuonPtFakeRate_histratio.png}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Scaled/coarse/ProbeTightMuonPtBJetGt0FakeRate_histratio.png}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Scaled/coarse/ProbeLooseORTightMuonPtFakeRate_histratio.png}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignMuonMuon/Scaled/coarse/ProbeLooseORTightMuonPtBJetGt0FakeRate_histratio.png}
%}
%\vspace{-10mm}\caption{Scaled....Transverse momentum distributions \pt\ of tight probe muons (top) and loose OR tight probe muons (bottom) passing signal selection criteria in the control Same-Sign $\mu-\mu$ control region without any additional requirement on $b$-jets in the event (left) and at least one $b$-jet (right). 
%The amount observed in data (black points) corresponds to $n$ (bottom) and $n_{\textrm{Tight}}$ (top) in Eq.~\ref{eq:fakerate}. 
%Meanwhile, the contribution determined in MC to come from real leptons (blue), photon conversion (red), heavy flavor (green) and light
%flavor (orange) are shown stacked on top of each other. 
%The difference between the data and MC does not effect the data-driven
%fake estimate but may have an impact on the composition estimate.
%}
%\label{fig:fakeEff_CRs_muon_stacked_scaled}
%\end{figure}

%\begin{figure}[h!]
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Scaled/coarse/ProbeTightElectronPtFakeRate_histratio.png}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Scaled/coarse/ProbeTightElectronPtBJetGt0FakeRate_histratio.png}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Scaled/coarse/ProbeLooseORTightElectronPtFakeRate_histratio.png}
%}
%\centering
%\subfigure{
%\includegraphics[width=0.45\columnwidth]{figures/fakes_bkg/CRs/SameSignElectronMuon/Scaled/coarse/ProbeLooseORTightElectronPtBJetGt0FakeRate_histratio.png}
%}
%\vspace{-10mm}\caption{Scaled...Transverse momentum distributions \pt\ of tight probe electron (top) and loose or tight probe electrons (bottom) passing signal selection criteria in the Same-Sign $e-\mu$ control region without any additional requirement on $b$-jets in the event (left) and at least one $b$-jet (right).
%The amount observed in data (black points) corresponds to $n$ (bottom) and $n_{\textrm{Tight}}$ (top) in Eq.~\ref{eq:fakerate}. 
%Meanwhile, the contribution determined in MC to come from real leptons (blue), photon conversion (red), heavy flavor (green) and light
%flavor (orange) are shown stacked on top of each other.
%The difference between the data and MC does not effect the data-driven
%fake estimate but may have an impact on the composition estimate.
%}
%\label{fig:fakeEff_CRs_electron_stacked_scaled}
%\end{figure}


\begin{table}[ht!]
\centering
\input{tables/ElectronCRComposition.tex}
\caption{
Composition of fake electrons taken from  MC events in the same-sign electron-muon di-lepton control regions
used to extract electron fake rates. The composition is split as either Heavy Flavor (HF), Photon
Conversion (PC), and Light Flavor (LF) are shown. In the ``PC subtracted'' case, the PC component
has been explicitly removed.  This corresponds to the scenario ultimately used in the
fake rate estimation.
}
\label{table:CompositionElectronCR}
\end{table}

\begin{table}[ht!]
\centering
\input{tables/ElectronSRComposition.tex}
\caption{
Composition of fake electrons taken from  MC events in the event pre-selection and regions close to the signal regions used in the analysis. 
The composition is split as either Heavy Flavor (HF) or Light Flavor (LF). 
}
\label{table:CompositionElectronSR}
\end{table}


\begin{table}[ht!]
\centering
\input{tables/MuonCRComposition.tex}
\caption{
Composition of fake muons taken from  MC events in the event pre-selection and regions close to the signal regions used in the analysis. 
The composition is split as either Heavy Flavor (HF), Photon
Conversion (PC), and Light Flavor (LF) are shown. The photon conversion component
is measured to be negligible. No PC subtraction is performed.
}
\label{table:CompositionMuonCR}
\end{table}

\begin{table}[ht!]
\centering
\input{tables/MuonSRComposition.tex}
\caption{
Composition of fake muons taken from  MC events in the same-sign muon-muon di-lepton control regions
used to extract the muon fake rates. The composition is split into either Heavy Flavor (HF) or Light Flavor (LF). 
}
\label{table:CompositionMuonSR}
\end{table}

\clearpage
\subsubsection{Fake lepton background validation}

A Monte Carlo closure test of the generalized matrix method is performed. The fake rates are computed from MC samples in the di-lepton control regions defined in section~\ref{sec:fakecomposition}, and the method is then applied on the most important MC samples contributing to the event pre-selection: $Z$+jets and $t\bar{t}$. The event pre-selection is used for this test, because the statistics available for the MC samples containing fake leptons in the signal region is too small to be able to draw any conclusion. Figure~\ref{fig:MCFakeRatesClosure}, show the MC fake rates obtained from the CR, while figure~\ref{fig:MCClosureCheckMatrixMethod} show the MC agreement with the MC events re-weighted using the generalized matrix method in the event pre-selection region, for the third-leading lepton $\pt$ and the $\met$ distribution. As it can be seen the shape agreement and the overall normalization are pretty good, showing that the matrix method is performing well.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.42\columnwidth]{figures/ClosureCheck_MatrixMethod/ElFakeRates_MC_topZjets_new.pdf}
\includegraphics[width=0.42\columnwidth]{figures/ClosureCheck_MatrixMethod/MuFakeRates_MC_topZjets_new.pdf}
\caption{Distribution of the fake rates obtained from MC samples in the di-lepton control regions. The errors shown here are statistical only. These rates are used to performed a MC closure check of the global matrix method.}
\label{fig:MCFakeRatesClosure}
\end{figure}

\begin{figure}[ht!]
\centering
\includegraphics[width=0.42\columnwidth]{figures/ClosureCheck_MatrixMethod/PtThirdLepSignal_TTT_total_new.pdf}
\includegraphics[width=0.42\columnwidth]{figures/ClosureCheck_MatrixMethod/VR_PMET_lepTTT_total_new.pdf}
\caption{Distributions of the third leading lepton $\pt$ and $\met$ in the event pre-selection region, for $Z$+jets and $t\bar{t}$, compared to events from these samples re-weighted using the global matrix method and the rates shown in Figure~\ref{fig:MCFakeRatesClosure}. Good agreement is observed}
\label{fig:MCClosureCheckMatrixMethod}
\end{figure}




The ability of the generalized matrix method just described to model accurately
the fake lepton background is tested in a control region designed to be enhanced
in the fake lepton background while maintaining orthogonality with the signal
regions described in Section~\ref{sec:signal_regions}. The control region 
starts by using the event pre-selection region described in Section~\ref{sec:preselection}. To reduce contamination in the 
control region from the $WZ$ process, it is required that none
of the three leptons selected form a Same-Flavor Opposite-Sign lepton pair.
Finally, to ensure orthogonality with the signal regions which require that no
$b$-tagged jets are present in the event, this control region requires
the presence of at least one $b$-tagged jet in the event. 

This control region
is clearly dominated by the data-driven fake lepton background as can
be seen in Fig.~\ref{fig:FakeCR} and in Table~\ref{tab:FakeCR}. 
Furthermore, Table~\ref{tab:FakeCR} shows good agreement between data
and the fake background modeling on the total event yield, which is within 
the statistical uncertainties.  One can even see from
Fig.~\ref{fig:FakeCR} that the shape description does a reasonable job,
although the statistical uncertainty is a bit too large to draw strong conclusions.
One can also see that the systematic uncertainty easily covers most
of the differences that are observed. Thus, we conclude that the fake background
description is working and may be used in our signal regions.  Especially since
the fake background is most important in the 0 SFOS region (described in more
detail in Section~\ref{sec:signal_regions}) which differs primarily from this
control region only by the $b$-veto requirement.




\begin{figure}[ht!]
\centering
\includegraphics[width=0.3\columnwidth]{figures/Fake_CR/LeadingLeptonPt_histratio.eps}
\includegraphics[width=0.3\columnwidth]{figures/Fake_CR/SubleadingLeptonPt_histratio.eps}
\includegraphics[width=0.3\columnwidth]{figures/Fake_CR/MinimumLeptonPt_histratio.eps}
\includegraphics[width=0.3\columnwidth]{figures/Fake_CR/MET_Et_histratio.eps}
\includegraphics[width=0.3\columnwidth]{figures/Fake_CR/NBTaggedJets_histratio.eps}
\includegraphics[width=0.3\columnwidth]{figures/Fake_CR/NJets_histratio.eps}
\includegraphics[width=0.3\columnwidth]{figures/Fake_CR/NMuons_histratio.eps}
\caption{Distributions in a control region designed to study the data-driven fake lepton background estimate.  The selection used is as follows: Event pre-selection + 0 SFOS + at least 1 $b$-jet.  Good agreement is observed}
\label{fig:FakeCR}
\end{figure}

\begin{table}[ht!]
\centering
\input{tables/FakeCR_Yields.tex}
\caption{Expected and observed yields for the fake lepton control region.}
\label{tab:FakeCR}
\end{table}


